from mediawiki import MediaWiki
wikipedia = MediaWiki()
wikipedia.page('List of Victorias Secret models').links
Victorias_secret_models = wikipedia.page('List of Victorias Secret models').links
models = Victorias_secret_models[::2]
models_final = models[0:-2]
models_final

import pandas as pd
df = pd.DataFrame(columns=["Model_name", "Summary_en"])
df["Model_name"] = pd.Series(models_final)
df


wikipedia.set_api_url(api_url='https://{lang}.wikipedia.org/w/api.php', lang='en')

summary_en = []
for name in models_final:
    if len(wikipedia.search(name)) == False:
        summary_en.append("None")
    else:
        summary_en.append(wikipedia.summary(name, sentences=1))
df["Summary_en"] = pd.Series(summary_en)
df

df1 = df.drop(df.index[[5, 16]]) #2 models didn't have a place of birth, so I dropped the rows 
df2 = df1.reset_index(drop=True) #after that I reset the index
models_final_final = list(df2['Model_name'])#and created a new list out of the column
models_final_final #so there would be no error afterwards

import re
birth_places = []

for model in models_final_final:
    model_wiki_name = wikipedia.search(model, results=1)[0]
    html = wikipedia.page(model_wiki_name).html
    a = re.findall(r'class="birthplace"><a href=(.*?)</td></tr><tr><th', html)
    birth_places.append(a)
df2["Birth_places"] = birth_places
df2

birth_places = []
for model in models_final_final:
    model_wiki_name = wikipedia.search(model, results = 1)[0]
    html = wikipedia.page(model_wiki_name).html
    a = re.findall(r'class="birthplace"><a href=(.*?)</td></tr><tr><th', html)
    b = ''.join(a)
    x = re.sub('<.*?>','', b)
    y = re.sub('[^a-zA-Z ]+','', x) #here I removed all symbols and URL tags
    z = y.split()[-1] #the results were quite messy, so I just converted the string back to list and sliced it
    birth_places.append(z)
df2["Birth_places"] = birth_places
df2

df3 = df2.replace(['information','Union', 'York', 'Islands'],['US', 'Soviet Union', 'US', 'Cayman Islands'])
df3 #manually replaced four places of birth that didn't follow the pattern

languages_available = []
for model in models_final_final:
    model_languages = wikipedia.page(model).langlinks
    languages_available.append(model_languages.keys())
df3["Languages"] = languages_available
df3

birth_dates = []

for model in models_final_final:
    model_wikipedia_name = wikipedia.search(model, results=1)[0]
    html = wikipedia.page(model_wikipedia_name).html
    k = re.findall(r'<span class="bday">(.*?)</span>', html)
    u = ''.join(k)
    birth_dates.append(u)
    
df3["Birth_dates"] = birth_dates
df3

countries_of_birth = df3.Birth_places.value_counts()
colors = ['pink', 'silver', 'lightsteelblue', 'thistle', 'mistyrose', 'lavender', 'papayawhip', 'rosybrown', 'azure' ]
explode = (0.07, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
countries_of_birth.plot.pie(figsize=(10, 10), colors=colors, explode = explode,autopct='%1.0f%%')
